{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aebd460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "\n",
    "# 1. 多模态数据集类（支持样本索引和标签）\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, image_data=None, text_data=None, vector_data=None, targets=None, is_test=False, device=device):\n",
    "        self.image_data = image_data\n",
    "        self.text_data = text_data\n",
    "        self.vector_data = vector_data\n",
    "        self.targets = targets  # 标签（y）\n",
    "        self.is_test = is_test\n",
    "        self.device = device\n",
    "        \n",
    "        # 确定样本数量\n",
    "        if image_data is not None:\n",
    "            self.num_samples = len(image_data)\n",
    "        elif text_data is not None:\n",
    "            self.num_samples = len(text_data)\n",
    "        else:\n",
    "            self.num_samples = len(vector_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'index': idx}  # 样本索引\n",
    "        if self.image_data is not None:\n",
    "            sample['image'] = torch.tensor(self.image_data[idx], dtype=torch.float32).to(self.device)\n",
    "        if self.text_data is not None:\n",
    "            sample['text'] = torch.tensor(self.text_data[idx], dtype=torch.float32).to(self.device)\n",
    "        if self.vector_data is not None:\n",
    "            sample['vector'] = torch.tensor(self.vector_data[idx], dtype=torch.float32).to(self.device)\n",
    "        if self.targets is not None:\n",
    "            sample['target'] = torch.tensor(self.targets[idx], dtype=torch.float32).to(self.device)  # 标签\n",
    "        return sample\n",
    "\n",
    "\n",
    "# 2. 模态编码器（保持不变）\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3)\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(3)\n",
    "        )\n",
    "        self.spatial_attn = nn.Sequential(\n",
    "            nn.Conv2d(3, 1, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(3 * 8 * 8, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_block1(x) + x\n",
    "        x2 = self.conv_block2(x1) + F.interpolate(x1, size=x1.shape[-1]//2)\n",
    "        x3 = self.conv_block3(x2) + F.interpolate(x2, size=x2.shape[-1]//2)\n",
    "        attn = self.spatial_attn(x3)\n",
    "        x3 = x3 * attn\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        return self.fc(x3)\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=50, hidden_dim=64, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.text_attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        attn_weights = F.softmax(self.text_attn(out).squeeze(-1), dim=1)\n",
    "        weighted_out = torch.bmm(attn_weights.unsqueeze(1), out).squeeze(1)\n",
    "        return self.fc(weighted_out)\n",
    "\n",
    "\n",
    "class VectorEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=32, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "# 3. 多模态融合模型（保持不变）\n",
    "class MultimodalEncoder(nn.Module):\n",
    "    def __init__(self, image_encoder, text_encoder, vector_encoder, latent_dim=128, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "        self.vector_encoder = vector_encoder\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.modal_weight = nn.Parameter(torch.ones(3))\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=128, num_heads=4, batch_first=True)\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(128 * 3, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim)\n",
    "        )\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, return_embedding=False):\n",
    "        batch_size = next(iter(v for k, v in x.items() if k != 'index')).size(0)\n",
    "        \n",
    "        img_feat = self.image_encoder(x['image']) if 'image' in x else torch.zeros(batch_size, 128).to(device)\n",
    "        text_feat = self.text_encoder(x['text']) if 'text' in x else torch.zeros(batch_size, 128).to(device)\n",
    "        vec_feat = self.vector_encoder(x['vector']) if 'vector' in x else torch.zeros(batch_size, 128).to(device)\n",
    "        \n",
    "        img_feat_expand = img_feat.unsqueeze(1)\n",
    "        text_feat_expand = text_feat.unsqueeze(1)\n",
    "        vec_feat_expand = vec_feat.unsqueeze(1)\n",
    "        \n",
    "        text_attended, _ = self.cross_attn(text_feat_expand, img_feat_expand, img_feat_expand)\n",
    "        vec_attended, _ = self.cross_attn(vec_feat_expand, img_feat_expand, img_feat_expand)\n",
    "        \n",
    "        weights = F.softmax(self.modal_weight, dim=0)\n",
    "        img_feat_weighted = img_feat * weights[0]\n",
    "        text_feat_weighted = text_attended.squeeze(1) * weights[1]\n",
    "        vec_feat_weighted = vec_attended.squeeze(1) * weights[2]\n",
    "        \n",
    "        fused = torch.cat([img_feat_weighted, text_feat_weighted, vec_feat_weighted], dim=1)\n",
    "        unified_embedding = F.relu(self.fusion(fused))  # 统一表征（特征）\n",
    "        output = self.regressor(unified_embedding)\n",
    "        projection = self.projection(unified_embedding)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return output, projection, unified_embedding\n",
    "        return output, projection\n",
    "\n",
    "\n",
    "# 4. 联邦学习客户端（支持训练集+测试集特征提取，含标签）\n",
    "class Client:\n",
    "    def __init__(self, client_id, model, train_dataset, test_dataset=None, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.model = copy.deepcopy(model).to(device)\n",
    "        self.train_dataset = train_dataset  # 本地训练集\n",
    "        self.test_dataset = test_dataset    # 本地测试集\n",
    "        self.train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        self.train_feature_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # 提取特征用（不打乱）\n",
    "        self.test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False) if test_dataset else None\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.local_epochs = 3\n",
    "        \n",
    "        # 互信息映射函数（保持不变）\n",
    "        self.f_map = nn.Sequential(\n",
    "            nn.Linear(model.latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        ).to(device)\n",
    "        for param in self.f_map.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # 损失函数（保持不变）\n",
    "    def compute_mi_loss_Y_Z(self, Z, Y):\n",
    "        f_Z = self.f_map(Z)\n",
    "        f_Z_norm = (f_Z - f_Z.mean(dim=0)) / (f_Z.std(dim=0) + 1e-8)\n",
    "        Y_norm = (Y - Y.mean(dim=0)) / (Y.std(dim=0) + 1e-8)\n",
    "        cov = torch.cov(torch.cat([f_Z_norm, Y_norm], dim=1).T)[0, 1]\n",
    "        corr = cov / (torch.std(f_Z_norm) * torch.std(Y_norm) + 1e-8)\n",
    "        return -torch.log(torch.abs(corr) + 1e-8)\n",
    "\n",
    "    def compute_kl_loss_modal(self, modal_feats):\n",
    "        if len(modal_feats) < 2:\n",
    "            return 0.0\n",
    "        kl_total = 0.0\n",
    "        num_pairs = 0\n",
    "        var = nn.Parameter(torch.tensor(0.1)).to(device)\n",
    "        dist_list = [torch.distributions.Normal(feat, var) for feat in modal_feats]\n",
    "        \n",
    "        for i in range(len(dist_list)):\n",
    "            for j in range(i+1, len(dist_list)):\n",
    "                kl_ij = torch.distributions.kl.kl_divergence(dist_list[i], dist_list[j]).mean()\n",
    "                kl_ji = torch.distributions.kl.kl_divergence(dist_list[j], dist_list[i]).mean()\n",
    "                kl_total += (kl_ij + kl_ji) / 2\n",
    "                num_pairs += 1\n",
    "        return kl_total / num_pairs\n",
    "\n",
    "    def compute_contrastive_loss_anti_forget(self, current_Z, prev_global_Z, history_global_Zs, temperature=0.5):\n",
    "        current_Z_norm = F.normalize(current_Z, dim=1)\n",
    "        prev_global_Z_norm = F.normalize(prev_global_Z, dim=1)\n",
    "        \n",
    "        pos_samples = prev_global_Z_norm\n",
    "        if history_global_Zs:\n",
    "            neg_samples = torch.cat([F.normalize(emb, dim=1) for emb in history_global_Zs], dim=0)\n",
    "        else:\n",
    "            neg_samples = current_Z_norm[torch.randperm(current_Z_norm.size(0))]\n",
    "        \n",
    "        pos_sim = torch.matmul(current_Z_norm, pos_samples.T).diag() / temperature\n",
    "        neg_sim = torch.matmul(current_Z_norm, neg_samples.T) / temperature\n",
    "        logits = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)\n",
    "        labels = torch.zeros(logits.size(0), dtype=torch.long).to(device)\n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def local_train(self, global_model, prev_global_Z, history_global_Zs, mu=0.01):\n",
    "        \"\"\"本地训练\"\"\"\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for epoch in range(self.local_epochs):\n",
    "            for batch in self.train_dataloader:\n",
    "                current_pred, _, current_Z = self.model(batch, return_embedding=True)\n",
    "                \n",
    "                modal_feats = []\n",
    "                if 'image' in batch:\n",
    "                    modal_feats.append(self.model.image_encoder(batch['image']))\n",
    "                if 'text' in batch:\n",
    "                    modal_feats.append(self.model.text_encoder(batch['text']))\n",
    "                if 'vector' in batch:\n",
    "                    modal_feats.append(self.model.vector_encoder(batch['vector']))\n",
    "                \n",
    "                reg_loss = F.mse_loss(current_pred.squeeze(), batch['target'])\n",
    "                mi_loss = self.compute_mi_loss_Y_Z(current_Z, batch['target'].unsqueeze(1))\n",
    "                kl_loss = self.compute_kl_loss_modal(modal_feats)\n",
    "                contrast_loss = self.compute_contrastive_loss_anti_forget(\n",
    "                    current_Z, prev_global_Z, history_global_Zs\n",
    "                )\n",
    "                \n",
    "                loss = reg_loss + mu * (mi_loss + kl_loss + contrast_loss)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / (self.local_epochs * len(self.train_dataloader))\n",
    "        print(f\"客户端 {self.client_id} 平均损失: {avg_loss:.4f}\")\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def extract_train_features(self, use_global_model=False, global_model=None):\n",
    "        \"\"\"提取训练集特征，与对应标签（y）一起返回\"\"\"\n",
    "        # 选择模型（全局或本地）\n",
    "        model = global_model if (use_global_model and global_model) else self.model\n",
    "        model.eval()\n",
    "        all_features = []\n",
    "        all_indices = []  # 训练样本索引\n",
    "        all_targets = []  # 训练样本标签（y）\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.train_feature_dataloader:\n",
    "                _, _, emb = model(batch, return_embedding=True)\n",
    "                all_features.append(emb.cpu())\n",
    "                all_indices.extend(batch['index'].cpu().numpy())\n",
    "                all_targets.extend(batch['target'].cpu().numpy())  # 收集标签\n",
    "        \n",
    "        model.train()\n",
    "        # 合并结果\n",
    "        features_np = torch.cat(all_features, dim=0).numpy()\n",
    "        targets_np = np.array(all_targets)\n",
    "        \n",
    "        return {\n",
    "            'client_id': self.client_id,\n",
    "            'train_indices': all_indices,\n",
    "            'train_features': features_np,  # 训练集特征 (N, 128)\n",
    "            'train_targets': targets_np     # 对应标签 (N,)\n",
    "        }\n",
    "\n",
    "    def extract_test_features(self, use_global_model=False, global_model=None):\n",
    "        \"\"\"提取测试集特征\"\"\"\n",
    "        if not self.test_dataset:\n",
    "            return None\n",
    "        \n",
    "        model = global_model if (use_global_model and global_model) else self.model\n",
    "        model.eval()\n",
    "        all_features = []\n",
    "        all_indices = []\n",
    "        all_preds = []\n",
    "        all_targets = []  # 测试集标签（如有）\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_dataloader:\n",
    "                pred, _, emb = model(batch, return_embedding=True)\n",
    "                all_features.append(emb.cpu())\n",
    "                all_indices.extend(batch['index'].cpu().numpy())\n",
    "                all_preds.append(pred.squeeze().cpu().numpy())\n",
    "                if 'target' in batch:\n",
    "                    all_targets.extend(batch['target'].cpu().numpy())  # 测试集标签\n",
    "        \n",
    "        model.train()\n",
    "        features_np = torch.cat(all_features, dim=0).numpy()\n",
    "        preds_np = np.concatenate(all_preds, axis=0)\n",
    "        targets_np = np.array(all_targets) if all_targets else None\n",
    "        \n",
    "        return {\n",
    "            'client_id': self.client_id,\n",
    "            'test_indices': all_indices,\n",
    "            'test_features': features_np,  # 测试集特征 (N, 128)\n",
    "            'test_preds': preds_np,         # 预测值 (N,)\n",
    "            'test_targets': targets_np      # 测试集标签（如有）\n",
    "        }\n",
    "\n",
    "\n",
    "# 5. 联邦学习服务器（协调训练集+测试集特征提取）\n",
    "class Server:\n",
    "    def __init__(self, model, num_clients):\n",
    "        self.global_model = copy.deepcopy(model).to(device)\n",
    "        self.num_clients = num_clients\n",
    "        self.clients = []\n",
    "        self.history_global_embs = []\n",
    "        self.latent_dim = model.latent_dim\n",
    "\n",
    "    def add_client(self, client):\n",
    "        self.clients.append(client)\n",
    "\n",
    "    def aggregate_parameters(self, client_params_list):\n",
    "        \"\"\"参数聚合（保持不变）\"\"\"\n",
    "        aggregated_params = {\n",
    "            name: torch.zeros_like(param) \n",
    "            for name, param in self.global_model.state_dict().items()\n",
    "        }\n",
    "        \n",
    "        for params in client_params_list:\n",
    "            for name, param in params.items():\n",
    "                if 'num_batches_tracked' in name:\n",
    "                    aggregated_params[name] += param.long() // self.num_clients\n",
    "                else:\n",
    "                    aggregated_params[name] += param.to(aggregated_params[name].dtype) / self.num_clients\n",
    "        \n",
    "        self.global_model.load_state_dict(aggregated_params)\n",
    "        return self.global_model.state_dict()\n",
    "\n",
    "    def evaluate(self, test_dataset):\n",
    "        \"\"\"全局模型评估（保持不变）\"\"\"\n",
    "        if test_dataset is None:\n",
    "            return\n",
    "        self.global_model.eval()\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        total_mse = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                pred, _ = self.global_model(batch)\n",
    "                mse = F.mse_loss(pred.squeeze(), batch['target'], reduction='sum')\n",
    "                total_mse += mse.item()\n",
    "                total_samples += batch['target'].size(0)\n",
    "        \n",
    "        rmse = np.sqrt(total_mse / total_samples)\n",
    "        #print(f\"全局模型测试RMSE: {rmse:.4f}\")\n",
    "        self.global_model.train()\n",
    "        return rmse\n",
    "\n",
    "    def federated_train(self, rounds=5, global_test_dataset=None):\n",
    "        \"\"\"联邦训练主流程\"\"\"\n",
    "        for round_idx in range(rounds):\n",
    "            print(f\"\\n===== 联邦轮次 {round_idx + 1}/{rounds} =====\")\n",
    "            \n",
    "            client_params_list = []\n",
    "            \n",
    "            # 获取上一轮全局表征\n",
    "            if global_test_dataset and self.history_global_embs:\n",
    "                test_loader = DataLoader(global_test_dataset, batch_size=32, shuffle=False)\n",
    "                test_batch = next(iter(test_loader))\n",
    "                with torch.no_grad():\n",
    "                    _, _, prev_global_Z = self.global_model(test_batch, return_embedding=True)\n",
    "                prev_global_Z = prev_global_Z.detach()\n",
    "                history_global_Zs = [z.detach() for z in self.history_global_embs[-3:]]\n",
    "            else:\n",
    "                prev_global_Z = torch.zeros(32, self.latent_dim).to(device)\n",
    "                history_global_Zs = []\n",
    "            \n",
    "            # 客户端本地训练\n",
    "            for client in self.clients:\n",
    "                client_params = client.local_train(\n",
    "                    self.global_model, prev_global_Z, history_global_Zs\n",
    "                )\n",
    "                client_params_list.append(client_params)\n",
    "            \n",
    "            # 聚合参数\n",
    "            self.aggregate_parameters(client_params_list)\n",
    "            \n",
    "            # 评估\n",
    "            self.evaluate(global_test_dataset)\n",
    "        \n",
    "        return self.global_model\n",
    "\n",
    "    def get_all_client_features(self, use_global_model=True):\n",
    "        \"\"\"获取所有客户端的训练集+测试集特征（含标签）\"\"\"\n",
    "        all_train_features = []\n",
    "        all_test_features = []\n",
    "        \n",
    "        for client in self.clients:\n",
    "            # 提取训练集特征（含标签）\n",
    "            train_feats = client.extract_train_features(\n",
    "                use_global_model=use_global_model,\n",
    "                global_model=self.global_model if use_global_model else None\n",
    "            )\n",
    "            all_train_features.append(train_feats)\n",
    "            \n",
    "            # 提取测试集特征\n",
    "            test_feats = client.extract_test_features(\n",
    "                use_global_model=use_global_model,\n",
    "                global_model=self.global_model if use_global_model else None\n",
    "            )\n",
    "            if test_feats:\n",
    "                all_test_features.append(test_feats)\n",
    "        \n",
    "        return all_train_features, all_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bd0635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "客户端 1 - 训练样本: 666, 测试样本: 166\n",
      "客户端 2 - 训练样本: 666, 测试样本: 166\n",
      "客户端 3 - 训练样本: 668, 测试样本: 168\n"
     ]
    }
   ],
   "source": [
    "def generate_sim_data(num_samples=1000):\n",
    "    image_data = np.random.randn(num_samples, 3, 32, 32)#xpd矩阵\n",
    "    text_data = np.random.randn(num_samples, 10, 50)\n",
    "    vector_data = np.random.randn(num_samples, 32)\n",
    "    img=image_data \n",
    "    txt=text_data\n",
    "    vec=vector_data\n",
    "    targets = np.tanh(0.05*np.sum(img.reshape(img.shape[0], -1)[:,::10], axis=1)\n",
    "              + 0.05*np.sum(txt.reshape(txt.shape[0], -1)[:,::10], axis=1)\n",
    "              + 0.05*np.sum(vec[:,::10], axis=1))\n",
    "    return image_data, text_data, vector_data, targets\n",
    "\n",
    "# 生成数据\n",
    "train_image, train_text, train_vector, train_target = generate_sim_data(2000)\n",
    "global_test_image, global_test_text, global_test_vector, global_test_target = generate_sim_data(500)\n",
    "\n",
    "# 分配客户端数据\n",
    "import numpy as np  # 需导入numpy用于生成随机索引\n",
    "\n",
    "# 分配客户端数据\n",
    "client_train_datasets = []\n",
    "client_test_datasets = []\n",
    "\n",
    "# ---------------------- 训练集随机分配 ----------------------\n",
    "# 计算训练集总样本数\n",
    "n_train = len(train_image)  # 原代码中总训练样本为2000（可自动适配实际长度）\n",
    "# 计算每个客户端的训练样本数（尽量平均分配，余数补到最后一个客户端）\n",
    "client_train_sizes = [n_train // 3] * 3\n",
    "remaining_train = n_train % 3\n",
    "if remaining_train > 0:\n",
    "    client_train_sizes[-1] += remaining_train  # 余数加到最后一个客户端\n",
    "\n",
    "# 生成训练集的随机索引（打乱顺序后切分）\n",
    "train_indices = np.random.permutation(n_train)  # 生成0~n_train-1的随机排列\n",
    "current_train = 0\n",
    "client_train_indices = []\n",
    "for size in client_train_sizes:\n",
    "    # 切分随机索引，每个客户端对应一组不重叠的索引\n",
    "    client_train_indices.append(train_indices[current_train:current_train + size])\n",
    "    current_train += size\n",
    "\n",
    "# ---------------------- 测试集随机分配 ----------------------\n",
    "# 计算测试集总样本数\n",
    "n_test = len(global_test_image)  # 原代码中总测试样本为500（可自动适配实际长度）\n",
    "# 计算每个客户端的测试样本数（逻辑同训练集）\n",
    "client_test_sizes = [n_test // 3] * 3\n",
    "remaining_test = n_test % 3\n",
    "if remaining_test > 0:\n",
    "    client_test_sizes[-1] += remaining_test\n",
    "\n",
    "# 生成测试集的随机索引（打乱顺序后切分）\n",
    "test_indices = np.random.permutation(n_test)  # 生成0~n_test-1的随机排列\n",
    "current_test = 0\n",
    "client_test_indices = []\n",
    "for size in client_test_sizes:\n",
    "    client_test_indices.append(test_indices[current_test:current_test + size])\n",
    "    current_test += size\n",
    "\n",
    "# ---------------------- 为每个客户端分配数据 ----------------------\n",
    "for i in range(3):\n",
    "    # 训练集：使用当前客户端的随机索引\n",
    "    train_idx = client_train_indices[i]\n",
    "    train_data = MultimodalDataset(\n",
    "        image_data=train_image[train_idx],  # 按随机索引取数据\n",
    "        text_data=train_text[train_idx],\n",
    "        vector_data=train_vector[train_idx],\n",
    "        targets=train_target[train_idx],\n",
    "        is_test=False\n",
    "    )\n",
    "    client_train_datasets.append(train_data)\n",
    "\n",
    "    # 测试集：使用当前客户端的随机索引\n",
    "    test_idx = client_test_indices[i]\n",
    "    test_data = MultimodalDataset(\n",
    "        image_data=global_test_image[test_idx],\n",
    "        text_data=global_test_text[test_idx],\n",
    "        vector_data=global_test_vector[test_idx],\n",
    "        targets=global_test_target[test_idx],\n",
    "        is_test=True\n",
    "    )\n",
    "    client_test_datasets.append(test_data)\n",
    "    print(f\"客户端 {i+1} - 训练样本: {len(train_data)}, 测试样本: {len(test_data)}\")\n",
    "\n",
    "# 全局测试集保持不变\n",
    "global_test_dataset = MultimodalDataset(\n",
    "    image_data=global_test_image,\n",
    "    text_data=global_test_text,\n",
    "    vector_data=global_test_vector,\n",
    "    targets=global_test_target,\n",
    "    is_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595198b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始联邦训练...\n",
      "\n",
      "===== 联邦轮次 1/5 =====\n",
      "客户端 1 平均损失: 0.4946\n",
      "客户端 2 平均损失: 0.4887\n",
      "客户端 3 平均损失: 0.5231\n",
      "\n",
      "===== 联邦轮次 2/5 =====\n",
      "客户端 1 平均损失: 0.3151\n",
      "客户端 2 平均损失: 0.3812\n",
      "客户端 3 平均损失: 0.4399\n",
      "\n",
      "===== 联邦轮次 3/5 =====\n",
      "客户端 1 平均损失: 0.2257\n",
      "客户端 2 平均损失: 0.2273\n",
      "客户端 3 平均损失: 0.3021\n",
      "\n",
      "===== 联邦轮次 4/5 =====\n",
      "客户端 1 平均损失: 0.1726\n",
      "客户端 2 平均损失: 0.1679\n",
      "客户端 3 平均损失: 0.2169\n",
      "\n",
      "===== 联邦轮次 5/5 =====\n",
      "客户端 1 平均损失: 0.1368\n",
      "客户端 2 平均损失: 0.1321\n",
      "客户端 3 平均损失: 0.1707\n",
      "\n",
      "提取客户端特征...\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型和联邦系统\n",
    "img_encoder = ImageEncoder(output_dim=128)\n",
    "text_encoder = TextEncoder(input_dim=50, output_dim=128)\n",
    "vec_encoder = VectorEncoder(input_dim=32, output_dim=128)\n",
    "base_model = MultimodalEncoder(img_encoder, text_encoder, vec_encoder, latent_dim=128, output_dim=1)\n",
    "\n",
    "server = Server(base_model, num_clients=3)\n",
    "for i in range(3):\n",
    "    client = Client(\n",
    "        client_id=i+1,\n",
    "        model=base_model,\n",
    "        train_dataset=client_train_datasets[i],\n",
    "        test_dataset=client_test_datasets[i]\n",
    "    )\n",
    "    server.add_client(client)\n",
    "\n",
    "# 联邦训练\n",
    "print(\"\\n开始联邦训练...\")\n",
    "trained_global_model = server.federated_train(rounds=5, global_test_dataset=global_test_dataset)\n",
    "\n",
    "# 提取所有客户端的训练集+测试集特征（使用全局模型）\n",
    "print(\"\\n提取客户端特征...\")\n",
    "all_train_feats, all_test_feats = server.get_all_client_features(use_global_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2cda8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 训练集特征与标签 =====\n",
      "客户端 1 训练集:\n",
      "  样本数: 666\n",
      "  特征形状: (666, 128)\n",
      "客户端 2 训练集:\n",
      "  样本数: 666\n",
      "  特征形状: (666, 128)\n",
      "客户端 3 训练集:\n",
      "  样本数: 668\n",
      "  特征形状: (668, 128)\n",
      "===== 测试集特征与预测 =====\n",
      "客户端 1 测试集:\n",
      "  样本数: 166\n",
      "  特征形状: (166, 128)\n",
      "客户端 2 测试集:\n",
      "  样本数: 166\n",
      "  特征形状: (166, 128)\n",
      "客户端 3 测试集:\n",
      "  样本数: 168\n",
      "  特征形状: (168, 128)\n"
     ]
    }
   ],
   "source": [
    "# 输出训练集特征与标签\n",
    "print(\"\\n===== 训练集特征与标签 =====\")\n",
    "for tf in all_train_feats:\n",
    "    client_id = tf['client_id']\n",
    "    print(f\"客户端 {client_id} 训练集:\")\n",
    "    print(f\"  样本数: {len(tf['train_indices'])}\")\n",
    "    print(f\"  特征形状: {tf['train_features'].shape}\")\n",
    "    #print(f\"  第1个样本特征前5维: {tf['train_features'][0, :5].round(4)}\")\n",
    "    #print(f\"  第1个样本标签: {tf['train_targets'][0].round(4)}\\n\")  # 训练集标签\n",
    "\n",
    "# 输出测试集特征\n",
    "print(\"===== 测试集特征与预测 =====\")\n",
    "for tf in all_test_feats:\n",
    "    client_id = tf['client_id']\n",
    "    print(f\"客户端 {client_id} 测试集:\")\n",
    "    print(f\"  样本数: {len(tf['test_indices'])}\")\n",
    "    print(f\"  特征形状: {tf['test_features'].shape}\")\n",
    "    #print(f\"  第1个样本特征前5维: {tf['test_features'][0, :5].round(4)}\")\n",
    "    #print(f\"  第1个样本预测值: {tf['test_preds'][0].round(4)}\")\n",
    "    #print(f\"  第1个样本真实标签: {tf['test_targets'][0].round(4)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01644f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 模型训练与评估 =====\n",
      "处理客户端 1...\n",
      "处理客户端 2...\n",
      "处理客户端 3...\n",
      "\n",
      "===== 各客户端模型评估结果汇总 =====\n",
      "   客户端ID  训练样本数  测试样本数  特征维度  均方误差(MSE)\n",
      "0      1    666    166   128   0.369144\n",
      "1      2    666    166   128   0.398254\n",
      "2      3    668    168   128   0.394170\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 存储各客户端的评估结果\n",
    "results = []\n",
    "\n",
    "# 遍历每个客户端进行模型训练与评估\n",
    "print(\"\\n===== 模型训练与评估 =====\")\n",
    "for i in range(len(all_train_feats)):\n",
    "    # 获取当前客户端的训练数据和测试数据\n",
    "    train_data = all_train_feats[i]\n",
    "    test_data = all_test_feats[i]\n",
    "    client_id = train_data['client_id']\n",
    "    \n",
    "    print(f\"处理客户端 {client_id}...\")\n",
    "    \n",
    "    # 提取训练特征和标签\n",
    "    X_train = train_data['train_features']\n",
    "    y_train = train_data['train_targets']\n",
    "    \n",
    "    # 提取测试特征和真实标签\n",
    "    X_test = test_data['test_features']\n",
    "    y_test = test_data['test_targets']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    # 初始化并训练随机森林模型\n",
    "    rf_model =RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 在测试集上进行预测\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # 计算均方误差\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # 存储结果\n",
    "    results.append({\n",
    "        '客户端ID': client_id,\n",
    "        '训练样本数': len(train_data['train_indices']),\n",
    "        '测试样本数': len(test_data['test_indices']),\n",
    "        '特征维度': X_train.shape[1],\n",
    "        '均方误差(MSE)': round(mse, 6)\n",
    "    })\n",
    "    \n",
    "    # 保存预测结果到测试数据中（如果需要）\n",
    "    test_data['test_preds'] = y_pred\n",
    "\n",
    "# 汇总结果为表格\n",
    "results_df1 = pd.DataFrame(results)\n",
    "\n",
    "# 输出汇总表格\n",
    "print(\"\\n===== 各客户端模型评估结果汇总 =====\")\n",
    "print(results_df1)\n",
    "\n",
    "# 可选：将结果保存为CSV文件\n",
    "# results_df1.to_csv('client_model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cb778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 基线对比：PCA / TSVD / RP（+ OURS 占位） =====\n",
      "\n",
      "===== 四方法对比（仅你要求的列） =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>客户端ID</th>\n",
       "      <th>训练样本数</th>\n",
       "      <th>测试样本数</th>\n",
       "      <th>PCA总维度</th>\n",
       "      <th>图像维度</th>\n",
       "      <th>文本维度</th>\n",
       "      <th>向量维度</th>\n",
       "      <th>PCA降维RF-MSE</th>\n",
       "      <th>TSVD降维RF-MSE</th>\n",
       "      <th>RP降维RF-MSE</th>\n",
       "      <th>您的方法-MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>666</td>\n",
       "      <td>166</td>\n",
       "      <td>834</td>\n",
       "      <td>516</td>\n",
       "      <td>290</td>\n",
       "      <td>28</td>\n",
       "      <td>0.417373</td>\n",
       "      <td>0.462569</td>\n",
       "      <td>0.478529</td>\n",
       "      <td>0.369144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>666</td>\n",
       "      <td>166</td>\n",
       "      <td>834</td>\n",
       "      <td>516</td>\n",
       "      <td>290</td>\n",
       "      <td>28</td>\n",
       "      <td>0.433622</td>\n",
       "      <td>0.477654</td>\n",
       "      <td>0.434221</td>\n",
       "      <td>0.398254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>668</td>\n",
       "      <td>168</td>\n",
       "      <td>837</td>\n",
       "      <td>518</td>\n",
       "      <td>291</td>\n",
       "      <td>28</td>\n",
       "      <td>0.505412</td>\n",
       "      <td>0.453051</td>\n",
       "      <td>0.494973</td>\n",
       "      <td>0.39417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   客户端ID  训练样本数  测试样本数  PCA总维度  图像维度  文本维度  向量维度  PCA降维RF-MSE  TSVD降维RF-MSE  \\\n",
       "0      1    666    166     834   516   290    28     0.417373      0.462569   \n",
       "1      2    666    166     834   516   290    28     0.433622      0.477654   \n",
       "2      3    668    168     837   518   291    28     0.505412      0.453051   \n",
       "\n",
       "   RP降维RF-MSE  您的方法-MSE  \n",
       "0    0.478529  0.369144  \n",
       "1    0.434221  0.398254  \n",
       "2    0.494973   0.39417  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== 基线对比：PCA / TSVD / RP + OURS（占位） 一次性跑完并汇总 ====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "# -------------------------------\n",
    "# 你的原始 PCA 基线（保持不动）\n",
    "# -------------------------------\n",
    "def pca_multimodal_data_by_contribution(image, text, vector, contribution=0.95):\n",
    "    \"\"\"\n",
    "    对各模态特征分别做PCA降维，保留指定累计贡献率的特征\n",
    "    :param contribution: 累计贡献率阈值（如0.95表示保留95%的信息）\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    modal_dims = {}  # 记录各模态降维后的维度\n",
    "    \n",
    "    # 1. 图像特征PCA（按贡献率）\n",
    "    flat_image = image.reshape(image.shape[0], -1)  # 原始维度：3*32*32=3072\n",
    "    image_scaled = scaler.fit_transform(flat_image)\n",
    "    pca_image = PCA().fit(image_scaled)  # 先不指定n_components，计算所有主成分\n",
    "    image_cum_contrib = np.cumsum(pca_image.explained_variance_ratio_)\n",
    "    image_dim = np.argmax(image_cum_contrib >= contribution) + 1  # +1是因为索引从0开始\n",
    "    pca_image = PCA(n_components=image_dim)\n",
    "    image_pca = pca_image.fit_transform(image_scaled)\n",
    "    modal_dims['image'] = image_dim\n",
    "    modal_dims['image_contrib'] = image_cum_contrib[image_dim-1]  # 实际累计贡献率\n",
    "    \n",
    "    # 2. 文本特征PCA（按贡献率）\n",
    "    flat_text = text.reshape(text.shape[0], -1)  # 原始维度：10*50=500\n",
    "    text_scaled = scaler.fit_transform(flat_text)\n",
    "    pca_text = PCA().fit(text_scaled)\n",
    "    text_cum_contrib = np.cumsum(pca_text.explained_variance_ratio_)\n",
    "    text_dim = np.argmax(text_cum_contrib >= contribution) + 1\n",
    "    pca_text = PCA(n_components=text_dim)\n",
    "    text_pca = pca_text.fit_transform(text_scaled)\n",
    "    modal_dims['text'] = text_dim\n",
    "    modal_dims['text_contrib'] = text_cum_contrib[text_dim-1]\n",
    "    \n",
    "    # 3. 向量特征PCA（按贡献率，若原始维度低则可能不降维）\n",
    "    flat_vector = vector  # 原始维度：32\n",
    "    vector_scaled = scaler.fit_transform(flat_vector)\n",
    "    pca_vector = PCA().fit(vector_scaled)\n",
    "    vector_cum_contrib = np.cumsum(pca_vector.explained_variance_ratio_)\n",
    "    vector_dim = np.argmax(vector_cum_contrib >= contribution) + 1\n",
    "    vector_dim = min(vector_dim, flat_vector.shape[1])\n",
    "    pca_vector = PCA(n_components=vector_dim)\n",
    "    vector_pca = pca_vector.fit_transform(vector_scaled)\n",
    "    modal_dims['vector'] = vector_dim\n",
    "    modal_dims['vector_contrib'] = vector_cum_contrib[vector_dim-1]\n",
    "    \n",
    "    modal_dims['total'] = image_dim + text_dim + vector_dim\n",
    "    modal_dims['total_contrib'] = (image_dim * modal_dims['image_contrib'] + \n",
    "                                  text_dim * modal_dims['text_contrib'] + \n",
    "                                  vector_dim * modal_dims['vector_contrib']) / modal_dims['total']\n",
    "    return np.hstack([image_pca, text_pca, vector_pca]), modal_dims\n",
    "\n",
    "def train_rf_with_pca_contribution(train_data, test_data, client_id, contribution=0.95):\n",
    "    # 训练集\n",
    "    X_train, modal_dims = pca_multimodal_data_by_contribution(\n",
    "        train_data.image_data, train_data.text_data, train_data.vector_data, contribution=contribution\n",
    "    )\n",
    "    y_train = train_data.targets\n",
    "\n",
    "    # 测试集（严格复用“训练集的”Scaler和PCA）\n",
    "    scaler_img = StandardScaler()\n",
    "    flat_image_train = train_data.image_data.reshape(train_data.image_data.shape[0], -1)\n",
    "    flat_image_test  = test_data.image_data.reshape(test_data.image_data.shape[0], -1)\n",
    "    img_scaled_train = scaler_img.fit_transform(flat_image_train)\n",
    "    pca_image = PCA(n_components=modal_dims['image']).fit(img_scaled_train)\n",
    "    image_pca_test = pca_image.transform(scaler_img.transform(flat_image_test))\n",
    "\n",
    "    scaler_txt = StandardScaler()\n",
    "    flat_text_train = train_data.text_data.reshape(train_data.text_data.shape[0], -1)\n",
    "    flat_text_test  = test_data.text_data.reshape(test_data.text_data.shape[0], -1)\n",
    "    txt_scaled_train = scaler_txt.fit_transform(flat_text_train)\n",
    "    pca_text = PCA(n_components=modal_dims['text']).fit(txt_scaled_train)\n",
    "    text_pca_test = pca_text.transform(scaler_txt.transform(flat_text_test))\n",
    "\n",
    "    scaler_vec = StandardScaler()\n",
    "    vec_scaled_train = scaler_vec.fit_transform(train_data.vector_data)\n",
    "    pca_vector = PCA(n_components=modal_dims['vector']).fit(vec_scaled_train)\n",
    "    vector_pca_test = pca_vector.transform(scaler_vec.transform(test_data.vector_data))\n",
    "\n",
    "    X_test = np.hstack([image_pca_test, text_pca_test, vector_pca_test])\n",
    "    y_test = test_data.targets\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=5, max_features='auto', n_jobs=-1, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse, modal_dims\n",
    "\n",
    "# -------------------------------\n",
    "# Truncated SVD（LSA）基线：严格按“每模态独立标准化→训练拟合→测试复用”流程做\n",
    "# 维度选择：用训练集的奇异值能量累计达到 contribution 的最小维度\n",
    "# -------------------------------\n",
    "def _tsvd_dim_by_contrib(X_scaled, contribution=0.95):\n",
    "    # 用训练集的奇异值估计累计方差占比\n",
    "    s = np.linalg.svd(X_scaled, full_matrices=False, compute_uv=False)\n",
    "    var = (s**2) / (X_scaled.shape[0] - 1)\n",
    "    ratio = var / var.sum()\n",
    "    cum = np.cumsum(ratio)\n",
    "    dim = int(np.searchsorted(cum, contribution) + 1)\n",
    "    dim = max(1, min(dim, X_scaled.shape[1]))  # 安全界\n",
    "    return dim\n",
    "\n",
    "def train_rf_with_tsvd_contribution(train_data, test_data, contribution=0.95):\n",
    "    # 图像\n",
    "    scaler_img = StandardScaler()\n",
    "    Xi_tr = scaler_img.fit_transform(train_data.image_data.reshape(len(train_data), -1))\n",
    "    dim_i = _tsvd_dim_by_contrib(Xi_tr, contribution)\n",
    "    tsvd_img = TruncatedSVD(n_components=dim_i, random_state=0).fit(Xi_tr)\n",
    "    Xi_te = tsvd_img.transform(scaler_img.transform(test_data.image_data.reshape(len(test_data), -1)))\n",
    "\n",
    "    # 文本\n",
    "    scaler_txt = StandardScaler()\n",
    "    Xt_tr = scaler_txt.fit_transform(train_data.text_data.reshape(len(train_data), -1))\n",
    "    dim_t = _tsvd_dim_by_contrib(Xt_tr, contribution)\n",
    "    tsvd_txt = TruncatedSVD(n_components=dim_t, random_state=0).fit(Xt_tr)\n",
    "    Xt_te = tsvd_txt.transform(scaler_txt.transform(test_data.text_data.reshape(len(test_data), -1)))\n",
    "\n",
    "    # 向量\n",
    "    scaler_vec = StandardScaler()\n",
    "    Xv_tr = scaler_vec.fit_transform(train_data.vector_data)\n",
    "    dim_v = _tsvd_dim_by_contrib(Xv_tr, contribution)\n",
    "    tsvd_vec = TruncatedSVD(n_components=min(dim_v, Xv_tr.shape[1]), random_state=0).fit(Xv_tr)\n",
    "    Xv_te = tsvd_vec.transform(scaler_vec.transform(test_data.vector_data))\n",
    "\n",
    "    X_train = np.hstack([tsvd_img.transform(Xi_tr), tsvd_txt.transform(Xt_tr), tsvd_vec.transform(Xv_tr)])\n",
    "    X_test  = np.hstack([Xi_te, Xt_te, Xv_te])\n",
    "    y_train, y_test = train_data.targets, test_data.targets\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=5, max_features='auto', n_jobs=-1, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# -------------------------------\n",
    "# Random Projection（Gaussian）基线：\n",
    "# 维度对齐：为公平起见，RP 的每模态 n_components = PCA 得到的该模态维度\n",
    "# 严格“训练拟合→测试复用”流程\n",
    "# -------------------------------\n",
    "def train_rf_with_rp_fixed_dims(train_data, test_data, pca_modal_dims, rp_type='gaussian', rp_random_state=0):\n",
    "    # 图像\n",
    "    scaler_img = StandardScaler()\n",
    "    Xi_tr = scaler_img.fit_transform(train_data.image_data.reshape(len(train_data), -1))\n",
    "    Xi_te_src = scaler_img.transform(test_data.image_data.reshape(len(test_data), -1))\n",
    "    dim_i = pca_modal_dims['image']\n",
    "    rp_img = GaussianRandomProjection(n_components=min(dim_i, Xi_tr.shape[1]), random_state=rp_random_state).fit(Xi_tr)\n",
    "    Xi_tr_rp = rp_img.transform(Xi_tr)\n",
    "    Xi_te = rp_img.transform(Xi_te_src)\n",
    "\n",
    "    # 文本\n",
    "    scaler_txt = StandardScaler()\n",
    "    Xt_tr = scaler_txt.fit_transform(train_data.text_data.reshape(len(train_data), -1))\n",
    "    Xt_te_src = scaler_txt.transform(test_data.text_data.reshape(len(test_data), -1))\n",
    "    dim_t = pca_modal_dims['text']\n",
    "    rp_txt = GaussianRandomProjection(n_components=min(dim_t, Xt_tr.shape[1]), random_state=rp_random_state).fit(Xt_tr)\n",
    "    Xt_tr_rp = rp_txt.transform(Xt_tr)\n",
    "    Xt_te = rp_txt.transform(Xt_te_src)\n",
    "\n",
    "    # 向量\n",
    "    scaler_vec = StandardScaler()\n",
    "    Xv_tr = scaler_vec.fit_transform(train_data.vector_data)\n",
    "    Xv_te_src = scaler_vec.transform(test_data.vector_data)\n",
    "    dim_v = pca_modal_dims['vector']\n",
    "    rp_vec = GaussianRandomProjection(n_components=min(dim_v, Xv_tr.shape[1]), random_state=rp_random_state).fit(Xv_tr)\n",
    "    Xv_tr_rp = rp_vec.transform(Xv_tr)\n",
    "    Xv_te = rp_vec.transform(Xv_te_src)\n",
    "\n",
    "    X_train = np.hstack([Xi_tr_rp, Xt_tr_rp, Xv_tr_rp])\n",
    "    X_test  = np.hstack([Xi_te, Xt_te, Xv_te])\n",
    "    y_train, y_test = train_data.targets, test_data.targets\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=5, max_features='auto', n_jobs=-1, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# -------------------------------\n",
    "# 主流程（输出你指定的列，不加别的）\n",
    "# -------------------------------\n",
    "comparison_rows = []\n",
    "print(\"===== 基线对比：PCA / TSVD / RP（+ OURS 占位） =====\")\n",
    "for client_idx in range(3):\n",
    "    client_id = client_idx + 1\n",
    "    train_data = client_train_datasets[client_idx]\n",
    "    test_data  = client_test_datasets[client_idx]\n",
    "\n",
    "    # 1) PCA（给出各模态维度与总维度 + MSE）\n",
    "    pca_mse, pca_modal_dims = train_rf_with_pca_contribution(\n",
    "        train_data, test_data, client_id=client_id, contribution=0.90  # 你之前示例用的是 0.90\n",
    "    )\n",
    "\n",
    "    # 2) TSVD（维度通过训练集奇异值能量选取）\n",
    "    tsvd_mse = train_rf_with_tsvd_contribution(\n",
    "        train_data, test_data, contribution=0.90\n",
    "    )\n",
    "\n",
    "    # 3) RP（每模态维度 = PCA 对应模态维度，公平对齐）\n",
    "    rp_mse = train_rf_with_rp_fixed_dims(\n",
    "        train_data, test_data, pca_modal_dims=pca_modal_dims, rp_type='gaussian', rp_random_state=0\n",
    "    )\n",
    "\n",
    "    row = {\n",
    "        '客户端ID': client_id,\n",
    "        '训练样本数': len(train_data),\n",
    "        '测试样本数': len(test_data),\n",
    "        'PCA总维度': pca_modal_dims['total'],\n",
    "        '图像维度': pca_modal_dims['image'],\n",
    "        '文本维度': pca_modal_dims['text'],\n",
    "        '向量维度': pca_modal_dims['vector'],\n",
    "        'PCA降维RF-MSE': round(float(pca_mse), 6),\n",
    "        'TSVD降维RF-MSE': round(float(tsvd_mse), 6),\n",
    "        'RP降维RF-MSE': round(float(rp_mse), 6),\n",
    "        '您的方法-MSE': None  # 由你外部结果回填\n",
    "    }\n",
    "    comparison_rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(comparison_rows)\n",
    "\n",
    "# 若你已有 OURS 的 MSE 序列，可在此回填（例如来自 results_df1 的最后一列）：\n",
    "try:\n",
    "    your_method_mses = results_df1.iloc[:, -1]  # 你给的示例写法\n",
    "    for i in range(len(results_df)):\n",
    "        results_df.loc[i, '您的方法-MSE'] = round(float(your_method_mses[i]), 6)\n",
    "except Exception:\n",
    "    pass  # 没有就留空，后续你再回填\n",
    "\n",
    "print(\"\\n===== 四方法对比（仅你要求的列） =====\")\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepSumMoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
